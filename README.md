# A Paper List for Pre-Training Based Dialogue model

This is a paper list for the pre-training based dialogue models. It involve both task-oriented and open-domain dialogue models.

**Keyword**: *Dialgue model, Pre-training method, Natural Language Processing*

# Paper List

## Pre-Training Method

- Improving Language Understanding by Generative Pre-Training, OpenAI Blog, [[paper]](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
- Better Language Models and Their Implications, OpenAI Blog, [[paper]](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- ConveRT: Efficient and Accurate Conversational Representations from Transformers, Arxiv-2019, [[paper]](https://arxiv.org/abs/1911.03688)
- DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation, Arxiv-2019, [[paper]](https://arxiv.org/abs/1911.00536), [[code]](https://github.com/microsoft/DialoGPT)
- PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable, Arxiv-2019, [[paper]](https://arxiv.org/abs/1910.07931)
- Pre-training Based Text Generation MASS: Masked Sequence to Sequence Pre-training for Language Generation, ICML2019, [[paper]](https://arxiv.org/pdf/1905.02450), [[code]](https://github.com/microsoft/MASS)
- Unified Language Model Pre-training for Natural Language Understanding and Generation, NIPS2019, [[paper]](https://arxiv.org/abs/1905.03197), [[code]](https://github.com/microsoft/unilm)
- Pretraining Methods for Dialog Context Representation Learning, ACL2019, [[paper]](https://www.aclweb.org/anthology/P19-1373.pdf)
- Denoising based Sequence-to-Sequence Pre-training for Text Generation, EMNLP2019, [[paper]](https://arxiv.org/abs/1908.08206), [[code]](https://github.com/yuantiku/PoDA)
- Masking Orchestration: Multi-task Pretraining for Multi-role Dialogue Representation Learning, AAAI2020

## Task-Oriented Dialog

- Hello, It's GPT-2--How Can I Help You? Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems, WNGT2019, [[paper]](https://arxiv.org/abs/1907.05774)
- Task-oriented Dialog Alternating Roles Dialog Model with Large-scale Pre-trained Language Models, Arxiv-2019, [[paper]](https://arxiv.org/abs/1910.03756)
- Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual Task-oriented Dialogue Systems, AAAI2020, [[paper]](https://arxiv.org/pdf/1911.09273.pdf), [[code]](https://github.com/zliucr/mixed-language-training)

## Open-Domain Dialog

- Relevance-Promoting Language Model for Short-Text Conversation, AAAI-2020, [[paper]](https://arxiv.org/abs/1911.11489)
- Transfertransfo: A transfer learning approach for neural network based conversational agents, NeurIPS 2018 CAI Workshop, [[paper]](https://arxiv.org/abs/1901.08149)
- Large-scale transfer learning for natural language generation, ACL2019, [[paper]](https://www.aclweb.org/anthology/P19-1608/), [[code]](https://github.com/atselousov/transformer_chatbot_experiments)
- Persona-aware Dialogue Generation with Enriched Profile, AAAI2020, [[paper]](https://arxiv.org/abs/1901.09672)
- Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline, Arxiv2019, [[paper]](https://arxiv.org/abs/1912.02379)

## Pre-training Based Text Generation (Not Dialog)

- Few-shot NLG with Pre-trained Language Model, Arxiv-2019, [[paper]](https://arxiv.org/abs/1904.09521), [[code]](https://github.com/czyssrs/Few-Shot-NLG)
- Harnessing Pre-Trained Neural Networks with Rules for Formality Style Transfer, EMNLP-2019, [[paper]](https://www.aclweb.org/anthology/D19-1365/), [[code]](https://github.com/jimth001/formality_emnlp19)

## Copyright 
By Yinhe Zheng (zhengyinhe1@163.com)

## Acknowledgement
[truthless11](https://github.com/truthless11)

**Welcome to open an issue or make a pull request!**
